#!/usr/bin/env python3
"""
ä¸­æ–‡é…éŸ³ç”Ÿæˆè„šæœ¬ï¼ˆå…è´¹ç‰ˆï¼‰- ä½¿ç”¨Microsoft Edge TTS
ç”¨æ³•: python tts_free.py <chinese.srt> [output.mp3]
"""

import sys
import os
import asyncio
import tempfile
import subprocess
import pysrt
import edge_tts

# å¯ç”¨çš„ä¸­æ–‡å£°éŸ³
VOICES = {
    "xiaoxiao": "zh-CN-XiaoxiaoNeural",      # å¥³å£°ï¼Œæ¸©æŸ”
    "xiaoyi": "zh-CN-XiaoyiNeural",          # å¥³å£°ï¼Œæ´»æ³¼
    "yunjian": "zh-CN-YunjianNeural",        # ç”·å£°ï¼Œæ²‰ç¨³ï¼ˆæ¨èç§‘æ™®ï¼‰
    "yunxi": "zh-CN-YunxiNeural",            # ç”·å£°ï¼Œå¹´è½»
    "yunxia": "zh-CN-YunxiaNeural",          # ç”·å£°
    "yunyang": "zh-CN-YunyangNeural",        # ç”·å£°ï¼Œæ–°é—»æ’­éŸ³é£æ ¼
}

async def generate_audio_segment(text: str, voice: str, output_path: str):
    """ç”Ÿæˆå•æ¡éŸ³é¢‘"""
    communicate = edge_tts.Communicate(text, voice)
    await communicate.save(output_path)

def run_command(cmd, description):
    """æ‰§è¡Œå‘½ä»¤å¹¶åœ¨å¤±è´¥æ—¶é€€å‡º"""
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"âŒ å¤±è´¥: {description}")
        if result.stderr:
            print(result.stderr)
        sys.exit(1)
    return result

def mix_segments_with_timestamps(audio_segments, output_audio, temp_dir):
    """æŒ‰å­—å¹•æ—¶é—´è½´åˆå¹¶éŸ³é¢‘ç‰‡æ®µ"""
    if not audio_segments:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„éŸ³é¢‘ç‰‡æ®µ")
        sys.exit(1)

    filter_lines = []
    mix_inputs = []
    for idx, seg in enumerate(audio_segments):
        delay_ms = max(0, int(seg["start_ms"]))
        filter_lines.append(f"[{idx}:a]adelay={delay_ms}|{delay_ms}[a{idx}]")
        mix_inputs.append(f"[a{idx}]")

    filter_lines.append(
        "".join(mix_inputs)
        + f"amix=inputs={len(audio_segments)}:duration=longest:normalize=0[aout]"
    )

    filter_script = os.path.join(temp_dir, "mix.ffmpeg")
    with open(filter_script, "w") as f:
        f.write(";".join(filter_lines))

    cmd = ["ffmpeg", "-y"]
    for seg in audio_segments:
        cmd.extend(["-i", seg["path"]])
    cmd.extend([
        "-filter_complex_script", filter_script,
        "-map", "[aout]",
        "-c:a", "mp3",
        output_audio,
    ])
    run_command(cmd, "åˆå¹¶éŸ³é¢‘ç‰‡æ®µ")

async def generate_tts(
    input_srt: str,
    output_audio: str = None,
    voice_name: str = "yunxi",
    segment_timeout: int = 20,
    concurrency: int = 5,
):
    """ä»ä¸­æ–‡å­—å¹•ç”Ÿæˆé…éŸ³"""

    voice = VOICES.get(voice_name, VOICES["yunxi"])

    # è¯»å–å­—å¹•
    print(f"ğŸ“– è¯»å–å­—å¹•: {input_srt}")
    subs = pysrt.open(input_srt, encoding='utf-8')
    total = len(subs)
    print(f"   å…± {total} æ¡å­—å¹•")
    print(f"   ä½¿ç”¨å£°éŸ³: {voice_name} ({voice})")

    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp()
    audio_segments = []

    semaphore = asyncio.Semaphore(concurrency)

    async def synthesize_segment(index, sub, text, segment_path):
        async with semaphore:
            print(f"ğŸ™ï¸ ç”Ÿæˆé…éŸ³... {index}/{total}")
            try:
                await asyncio.wait_for(
                    generate_audio_segment(text, voice, segment_path),
                    timeout=segment_timeout
                )
                return {
                    "path": segment_path,
                    "start_ms": sub.start.ordinal,
                    "text": text,
                }
            except asyncio.TimeoutError:
                print(f"âš ï¸ è¶…æ—¶è·³è¿‡ ({index})")
            except Exception as e:
                print(f"âš ï¸ è·³è¿‡ ({index}): {e}")
            return None

    tasks = []
    for i, sub in enumerate(subs, start=1):
        text = sub.text.replace('\n', ' ').strip()
        if not text:
            continue
        segment_path = os.path.join(temp_dir, f"segment_{i:04d}.mp3")
        tasks.append(asyncio.create_task(
            synthesize_segment(i, sub, text, segment_path)
        ))

    results = await asyncio.gather(*tasks)
    audio_segments = [seg for seg in results if seg is not None]

    # åˆå¹¶éŸ³é¢‘
    if output_audio is None:
        base, _ = os.path.splitext(input_srt)
        output_audio = f"{base}_audio.mp3"

    print("ğŸ”§ åˆå¹¶éŸ³é¢‘ç‰‡æ®µï¼ˆæŒ‰å­—å¹•æ—¶é—´è½´ï¼‰...")
    mix_segments_with_timestamps(audio_segments, output_audio, temp_dir)
    print(f"âœ… é…éŸ³å®Œæˆ: {output_audio}")

    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    import shutil
    shutil.rmtree(temp_dir)

    return output_audio

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python tts_free.py <chinese.srt> [output.mp3] [voice] [concurrency]")
        print("\nå¯ç”¨å£°éŸ³:")
        for name, voice in VOICES.items():
            print(f"  {name}: {voice}")
        sys.exit(1)

    input_srt = sys.argv[1]
    output_audio = sys.argv[2] if len(sys.argv) > 2 else None
    voice = sys.argv[3] if len(sys.argv) > 3 else "yunxi"
    concurrency = int(sys.argv[4]) if len(sys.argv) > 4 else 5

    asyncio.run(generate_tts(input_srt, output_audio, voice, concurrency=concurrency))

if __name__ == "__main__":
    main()
